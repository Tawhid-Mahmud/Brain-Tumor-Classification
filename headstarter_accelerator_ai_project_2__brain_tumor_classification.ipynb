{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tawhid-Mahmud/Brain-Tumor-Classification/blob/main/headstarter_accelerator_ai_project_2__brain_tumor_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTUwNTwDCis5"
      },
      "outputs": [],
      "source": [
        "import os #helps us to access dataset that we will load\n",
        "import pandas as pd #data manipulation library\n",
        "import numpy as np #allow us to do numerical computing\n",
        "import matplotlib.pyplot as plt #visualize our data\n",
        "import seaborn as sns #more advanced visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloads the dataset from kaggle"
      ],
      "metadata": {
        "id": "TAPGD7ooEm_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset --unzip"
      ],
      "metadata": {
        "id": "5Cq5eBOxEWOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_paths(path):\n",
        "  classes = []\n",
        "  class_paths = []\n",
        "\n",
        "  #iterate through directories in the training path\n",
        "  for label in os.listdir(path):\n",
        "    label_path = os.path.join(path, label)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(label_path):\n",
        "      # Iterate throug images in the label directory\n",
        "      for image in os.listdir(label_path):\n",
        "        image_path = os.path.join(label_path, image)\n",
        "\n",
        "        # Add class and path to respective lists\n",
        "        classes.append(label)\n",
        "        class_paths.append(image_path)\n",
        "\n",
        "  # Create a DataFrame with the collected data\n",
        "  df = pd.DataFrame({\n",
        "      'Class Path': class_paths,\n",
        "      'Class': classes\n",
        "  })\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "r9Ir8fqjEkgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df = get_class_paths(\"/content/Training\")"
      ],
      "metadata": {
        "id": "Bb2s63qgGlez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df"
      ],
      "metadata": {
        "id": "bkQFxlA4Gvma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_df = get_class_paths(\"/content/Testing\")"
      ],
      "metadata": {
        "id": "zNrmb594Ha6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_df"
      ],
      "metadata": {
        "id": "uROXMZbLHjcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show count of the images in each class"
      ],
      "metadata": {
        "id": "YuUr4-1cHsxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data set count"
      ],
      "metadata": {
        "id": "Exad-ZQ6IqYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "ax = sns.countplot(data=tr_df, x=tr_df['Class'])"
      ],
      "metadata": {
        "id": "rZSmvHRcHk5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing data set count"
      ],
      "metadata": {
        "id": "BUwDHT80Iu9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "ax = sns.countplot(data=ts_df, x=ts_df['Class'])"
      ],
      "metadata": {
        "id": "zLqA9C8mIHrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential #neural network model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "60Qh3V_sI0SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df, ts_df = train_test_split(ts_df, test_size=0.5, stratify=ts_df['Class'])"
      ],
      "metadata": {
        "id": "b1EzdN_osNEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df"
      ],
      "metadata": {
        "id": "ACk62eXtsfk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_df"
      ],
      "metadata": {
        "id": "CW5HJMcSsjos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test different batch sizes 16,32,34,128"
      ],
      "metadata": {
        "id": "uDlrdQem7ZdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "#resize images to same size\n",
        "img_size = (299, 299)\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))\n",
        "ts_gen = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "Bvuhboho7CrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create 3 different flows training, validation, testing"
      ],
      "metadata": {
        "id": "IPUMgRk48YG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_gen = image_generator.flow_from_dataframe(\n",
        "    tr_df,\n",
        "    x_col='Class Path',\n",
        "    y_col='Class',\n",
        "    batch_size = batch_size,\n",
        "    target_size=img_size)\n",
        "\n",
        "valid_gen = image_generator.flow_from_dataframe(\n",
        "    valid_df,\n",
        "    x_col='Class Path',\n",
        "    y_col='Class',\n",
        "    batch_size = batch_size,\n",
        "    target_size=img_size)\n",
        "\n",
        "ts_gen = ts_gen.flow_from_dataframe(\n",
        "    ts_df,\n",
        "    x_col='Class Path',\n",
        "    y_col='Class',\n",
        "    batch_size = 16,\n",
        "    target_size=img_size, shuffle=False)"
      ],
      "metadata": {
        "id": "4GOq4pgW75_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(16):\n",
        "  plt.subplot(4, 4, i+1)\n",
        "  batch = next(tr_gen)\n",
        "  image = batch[0][0]\n",
        "  label = batch[1][0]\n",
        "  plt.imshow(image)\n",
        "\n",
        "  # Get the class index\n",
        "  class_index = np.argmax(label)\n",
        "\n",
        "  # Get the list of class names and class indices\n",
        "  class_names = list(tr_gen.class_indices.keys())\n",
        "  class_indices = list(tr_gen.class_indices.values())\n",
        "\n",
        "  # Find the index of the class_index in the list of indices\n",
        "  index_position = class_indices.index(class_index)\n",
        "\n",
        "  # Get the class name using the index position\n",
        "  class_name = class_names[index_position]\n",
        "\n",
        "  plt.title(f\"Class: {class_name}\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9wPeOmrB91Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (299, 299, 3)\n",
        "\n",
        "base_model = tf.keras.applications.Xception (include_top= False,\n",
        "                                             weights= \"imagenet\",\n",
        "                                             input_shape= img_shape,\n",
        "                                             pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dropout(rate=0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(rate=0.25),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "JIZRCbylDi_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adamax(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "              Precision(),\n",
        "              Recall()])"
      ],
      "metadata": {
        "id": "_kCymTRuNfCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(tr_gen, epochs=5, validation_data=valid_gen)"
      ],
      "metadata": {
        "id": "JiN0xtBiNvtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation metrics from history\n",
        "metrics = ['accuracy', 'loss', 'precision', 'recall']\n",
        "tr_metrics = {m: hist.history [m] for m in metrics}\n",
        "val_metrics = {m: hist.history[f'val_{m}'] for m in metrics}\n",
        "\n",
        "# Find best epochs and values\n",
        "best_epochs = {}\n",
        "best_values = {}\n",
        "for m in metrics:\n",
        "  if m == 'loss':\n",
        "    idx = np.argmin (val_metrics [m])\n",
        "  else:\n",
        "    idx = np.argmax (val_metrics [m])\n",
        "  best_epochs [m] = idx + 1\n",
        "  best_values [m] = val_metrics [m] [idx]\n",
        "# Plot metrics\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "for i, metric in enumerate (metrics, 1):\n",
        "  plt.subplot(2, 2, i)\n",
        "  epochs = range (1, len(tr_metrics [metric]) + 1)\n",
        "\n",
        "  plt.plot(epochs, tr_metrics [metric], 'r', label=f'Training {metric}')\n",
        "  plt.plot(epochs, val_metrics [metric], 'g', label=f'Validation {metric}')\n",
        "  plt.scatter(best_epochs [metric], best_values [metric], s=150, c='blue',\n",
        "              label=f'Best epoch = {best_epochs [metric]}')\n",
        "  plt.title(f'Training and Validation {metric.title()}')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(metric.title())\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plt.suptitle( 'Model Training Metrics Over Epochs', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PCMBZWSw83gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = model.evaluate(tr_gen, verbose=1)\n",
        "valid_score = model.evaluate(valid_gen, verbose=1)\n",
        "test_score = model.evaluate(ts_gen, verbose=1)\n",
        "\n",
        "print(f\"Train Accuracy: {train_score[1]*100:.2f}%\")\n",
        "print(f\"Train loss: {train_score[0]:.4f}\")\n",
        "print(f\"\\n\\nValidation Accuracy: {valid_score[1]*100:.2f}%\")\n",
        "print(f\"Validation loss: {valid_score[0]:.4f}\")\n",
        "print(f\"\\n\\nTest Accuracy: {test_score[1]*100:.2f}%\")\n",
        "print(f\"Test loss: {test_score[0]:.4f}\")"
      ],
      "metadata": {
        "id": "y8LYEa31rtEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matricx"
      ],
      "metadata": {
        "id": "BD2t7gVpvaop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(ts_gen)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "class_dict = {\n",
        "    0: 'glioma_tumor',\n",
        "    1: 'meningioma_tumor',\n",
        "    2: 'no_tumor',\n",
        "    3: 'pituitary_tumor'\n",
        "}\n",
        "\n",
        "# Then create and display the confusion matrix\n",
        "cm = confusion_matrix(ts_gen.classes, y_pred)\n",
        "labels = list(class_dict.keys())\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NinrTI4HvfCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def predict(img_path: str) -> None:\n",
        "  # Get class labels\n",
        "  labels = list(class_dict.keys())\n",
        "\n",
        "  # Create figure\n",
        "  plt.figure(figsize=(6, 8))\n",
        "\n",
        "  # Load and preprocess image\n",
        "  img = Image.open(img_path)\n",
        "  resized_img = img.resize((299, 299))\n",
        "  img_array = np.asarray(resized_img)\n",
        "  img_array = np.expand_dims (img_array, axis=0) / 255.0\n",
        "\n",
        "  # Get model predictions\n",
        "  predictions = model.predict(img_array)\n",
        "  probabilities = list(predictions [0])\n",
        "\n",
        "  # Get predicted class\n",
        "  predicted_class_idx = np.argmax (probabilities)\n",
        "  predicted_class = class_dict[predicted_class_idx]\n",
        "\n",
        "  # Plot original image\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.imshow(resized_img)\n",
        "  plt.title(f\"Input MRI Image\\nPredicted: {predicted_class}\")\n",
        "\n",
        "  # Plot prediction probabilities\n",
        "  plt.subplot(2, 1, 2)\n",
        "  bars = plt.barh (labels, probabilities)\n",
        "  plt.xlabel(\"Probability\", fontsize=15)\n",
        "  plt.title(\"Class Probabilities\")\n",
        "\n",
        "  # Add probability labels to bars\n",
        "  ax = plt.gca()\n",
        "  ax.bar_label(bars, fmt=\"%.2f\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  print (f\"\\nPredicted tumor type: {predicted_class}\")"
      ],
      "metadata": {
        "id": "CS6DvgV4yKRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"/content/Testing/meningioma/Te-meTr_0000.jpg\")"
      ],
      "metadata": {
        "id": "dOcy3IIQz5M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Th4b77RE0YgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"/content/Testing/meningioma/Te-meTr_0005.jpg\")"
      ],
      "metadata": {
        "id": "bIvzB3mF0XrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"xception_model.weights.h5\")"
      ],
      "metadata": {
        "id": "rNWfgK2K0aSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom CNN Model"
      ],
      "metadata": {
        "id": "PyrK4R_L1k44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "F6ypibfj1Vm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "img_size = (224, 224)\n",
        "\n",
        "image_generator = ImageDataGenerator (rescale=1/255, brightness_range=(0.8, 1.2))\n",
        "\n",
        "ts_gen = ImageDataGenerator (rescale=1/255)\n",
        "\n",
        "tr_gen = image_generator.flow_from_dataframe (tr_df, x_col='Class Path',\n",
        "                                              y_col='Class',\n",
        "                                              batch_size=batch_size,\n",
        "                                              target_size=img_size)\n",
        "\n",
        "valid_gen = image_generator.flow_from_dataframe(valid_df, x_col='Class Path',\n",
        "                                               y_col='Class',\n",
        "                                               batch_size=batch_size,\n",
        "                                               target_size=img_size)\n",
        "\n",
        "ts_gen = ts_gen.flow_from_dataframe (ts_df, x_col='Class Path',\n",
        "                                   y_col='Class',\n",
        "                                   batch_size=16,\n",
        "                                   target_size=img_size, shuffle=False)"
      ],
      "metadata": {
        "id": "H4n2ydlo2Jpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "cnn_model.add(Conv2D(512, (3, 3), padding='same', input_shape=(224,224,3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D (pool_size=(2, 2)))\n",
        "\n",
        "cnn_model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout (0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling2D (pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout (0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output for fully connected layers\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "#Fully connected layers\n",
        "cnn_model.add(Dense (256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "cnn_model.add(Dropout (0.35))\n",
        "\n",
        "cnn_model.add(Dense (4, activation='softmax')) # Output layer with 4 neurons for the 4 classes\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(Adamax (learning_rate=0.001), loss='categorical_crossentropy', metrics= ['accuracy', Precision(),Recall()])\n",
        "\n",
        " # Display the model summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "89JN0LTyqgG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model for longer"
      ],
      "metadata": {
        "id": "X6dmlOC4zya6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(tr_gen, epochs=8, validation_data=valid_gen)"
      ],
      "metadata": {
        "id": "UqtVzcDYuYdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation metrics from history\n",
        "metrics = ['accuracy', 'loss', 'precision_1', 'recall_1']\n",
        "tr_metrics = {m: history.history [m] for m in metrics}\n",
        "val_metrics = {m: history.history[f'val_{m}'] for m in metrics}\n",
        "\n",
        "# Find best epochs and values\n",
        "best_epochs = {}\n",
        "best_values = {}\n",
        "for m in metrics:\n",
        "  if m == 'loss':\n",
        "    idx = np.argmin (val_metrics [m])\n",
        "  else:\n",
        "    idx = np.argmax (val_metrics [m])\n",
        "  best_epochs [m] = idx + 1\n",
        "  best_values [m] = val_metrics [m] [idx]\n",
        "# Plot metrics\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "for i, metric in enumerate (metrics, 1):\n",
        "  plt.subplot(2, 2, i)\n",
        "  epochs = range (1, len(tr_metrics [metric]) + 1)\n",
        "\n",
        "  plt.plot(epochs, tr_metrics [metric], 'r', label=f'Training {metric}')\n",
        "  plt.plot(epochs, val_metrics [metric], 'g', label=f'Validation {metric}')\n",
        "  plt.scatter(best_epochs [metric], best_values [metric], s=150, c='blue',\n",
        "              label=f'Best epoch = {best_epochs [metric]}')\n",
        "  plt.title(f'Training and Validation {metric.title()}')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(metric.title())\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plt.suptitle( 'Model Training Metrics Over Epochs', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TTrnm7xVvQtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = cnn_model.evaluate(tr_gen, verbose=1)\n",
        "valid_score = cnn_model.evaluate(valid_gen, verbose=1)\n",
        "test_score = cnn_model.evaluate(ts_gen, verbose=1)\n",
        "\n",
        "print(f\"Train Accuracy: {train_score[1]*100:.2f}%\")\n",
        "print(f\"Train loss: {train_score[0]:.4f}\")\n",
        "print(f\"\\n\\nValidation Accuracy: {valid_score[1]*100:.2f}%\")\n",
        "print(f\"Validation loss: {valid_score[0]:.4f}\")\n",
        "print(f\"\\n\\nTest Accuracy: {test_score[1]*100:.2f}%\")\n",
        "print(f\"Test loss: {test_score[0]:.4f}\")"
      ],
      "metadata": {
        "id": "ZlHWUGmBy8i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#show confusion matrix"
      ],
      "metadata": {
        "id": "TE8-xeSqz7Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = cnn_model.predict(ts_gen)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "class_dict = {\n",
        "    0: 'glioma_tumor',\n",
        "    1: 'meningioma_tumor',\n",
        "    2: 'no_tumor',\n",
        "    3: 'pituitary_tumor'\n",
        "}\n",
        "\n",
        "# Then create and display the confusion matrix\n",
        "cm = confusion_matrix(ts_gen.classes, y_pred)\n",
        "labels = list(class_dict.keys())\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1j2CQz_3z6CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clr = classification_report(ts_gen.classes, y_pred)\n",
        "print(clr)"
      ],
      "metadata": {
        "id": "77x8hsWp0c-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.save(\"cnn_model.h5\")"
      ],
      "metadata": {
        "id": "X8JBrssk1Lop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part 2: Streamlit web app"
      ],
      "metadata": {
        "id": "Mbvd_9YI1kKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit pyngrok python-dotenv"
      ],
      "metadata": {
        "id": "t2zqQwuj1iXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "bvmGEppL2M7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "kb14EPXP3TNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "  os.system(\"streamlit run /content/app.py --server.port 8501\")"
      ],
      "metadata": {
        "id": "-E7Xvmqe31eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "output_dir = 'saliency_maps'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def generate_explanation(img_path, model_prediction, confidence) :\n",
        "\n",
        "    prompt = f\"\"\"You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n",
        "    The saliency map was generated by a deep learning model that was trained to classify brain tumors\n",
        "    as either glioma, meningioma, pituitary, or no tumor.\n",
        "\n",
        "    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n",
        "\n",
        "    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.\n",
        "\n",
        "    In your response:\n",
        "    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted\n",
        "    in light cyan, those are the regions where the model is focusing on.\n",
        "    - Explain possible reasons why the model made the prediction it did.\n",
        "    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'\n",
        "    in your explanation.\n",
        "    - Keep your explanation to 4 sentences max.\n",
        "\n",
        "    Let's think step by step about this. Verify step by step\n",
        "    \"\"\"\n",
        "    img = PIL.Image.open(img_path)\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "    response = model. generate_content ( [prompt, img] )\n",
        "    return response.text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_saliency_map(model, img_array, class_index, img_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "        img_tensor = tf.convert_to_tensor(img_array)\n",
        "        tape.watch(img_tensor)\n",
        "        predictions = model(img_tensor)\n",
        "        target_class = predictions[:, class_index]\n",
        "\n",
        "\n",
        "\n",
        "    gradients = tape. gradient (target_class, img_tensor)\n",
        "    gradients = tf.math.abs (gradients)\n",
        "    gradients = tf. reduce_max (gradients, axis =- 1)\n",
        "    gradients = gradients. numpy ( ) . squeeze()\n",
        "\n",
        "    # Resize gradients to match original image size\n",
        "    gradients = cv2. resize(gradients, img_size)\n",
        "\n",
        "    # Create a circular mask for the brain area\n",
        "    center = (gradients.shape [0] // 2, gradients. shape[1] // 2)\n",
        "    radius = min (center [0], center [1] ) - 10\n",
        "    y, x = np. ogrid [ : gradients. shape [0], : gradients. shape [1] ]\n",
        "    mask = (x- center[0]) ** 2 + (y - center[1]) ** 2 <= radius ** 2\n",
        "\n",
        "    # Apply mask to gradients\n",
        "    gradients = gradients * mask\n",
        "\n",
        "    # Normalize only the brain area\n",
        "    brain_gradients = gradients [mask]\n",
        "    if brain_gradients.max() > brain_gradients.min() :\n",
        "        brain_gradients = (brain_gradients - brain_gradients.min( ) ) / (brain_gradients.max( ) - brain_gradients.min( ))\n",
        "    gradients [mask] = brain_gradients\n",
        "\n",
        "    # Apply a higher threshold\n",
        "    threshold = np.percentile(gradients [mask], 80)\n",
        "    gradients [gradients < threshold] = 0\n",
        "\n",
        "    # Apply more aggressive smoothing\n",
        "    gradients = cv2. GaussianBlur(gradients, (11, 11), 0)\n",
        "\n",
        "    # Create a heatmap overlay with enhanced contrast\n",
        "    heatmap = cv2. applyColorMap(np.uint8(255 * gradients), cv2. COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize heatmap to match original image size\n",
        "    heatmap = cv2. resize(heatmap, img_size)\n",
        "\n",
        "    # Superimpose the heatmap on original image with increased opacity\n",
        "    original_img = image. img_to_array(img)\n",
        "    superimposed_img = heatmap * 0.7 + original_img * 0.3\n",
        "    superimposed_img = superimposed_img.astype(np.uint8)\n",
        "\n",
        "    img_path = os.path.join(output_dir, uploaded_file. name)\n",
        "    with open(img_path, \"wb\") as f:\n",
        "        f. write (uploaded_file. getbuffer ( ) )\n",
        "\n",
        "    saliency_map_path = f'saliency_maps/{uploaded_file. name}'\n",
        "\n",
        "    # Save the saliency map\n",
        "    cv2. imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "    return superimposed_img\n",
        "\n",
        "\n",
        "def load_xception_model(model_path):\n",
        "    img_shape=(299,299,3)\n",
        "    base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",\n",
        "                                                input_shape=img_shape, pooling='max')\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dropout(rate=0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(rate=0.25),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.build((None,) + img_shape)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(Adamax(learning_rate=0.001),\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics=['accuracy',\n",
        "                            Precision(),\n",
        "                            Recall()])\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"Brain Tumor Classification\")\n",
        "st.write(\"Upload an image of a brain MRI scan to classify.\")\n",
        "\n",
        "#create a variable\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\",\"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    selected_model = st.radio(\n",
        "        \"Select Model\",\n",
        "        (\"Transfer Learning - Xception\", \"Custom CNN\")\n",
        "    )\n",
        "    if selected_model == \"Transfer Learning - Xception\":\n",
        "        model = load_xception_model('/content/xception_model.weights.h5')  # Load the model using the function\n",
        "        img_size = (299, 299)\n",
        "    else:\n",
        "        model = load_model('/content/cnn_model.h5')\n",
        "        img_size = (224, 224)\n",
        "\n",
        "\n",
        "    labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']\n",
        "    img = image.load_img(uploaded_file, target_size = img_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /=255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Get the class with the highest probability\n",
        "    class_index = np.argmax(prediction[0])\n",
        "    result = labels[class_index]\n",
        "\n",
        "    st.write(f\"Prediction Class: {result}\")\n",
        "    st.write(\"Prediction:\")\n",
        "    for label, prob in zip(labels, prediction[0]):\n",
        "        st.write(f\"{label}: {prob:.4f}\")\n",
        "\n",
        "\n",
        "    saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)\n",
        "    with col2:\n",
        "        st.image(saliency_map, caption='Saliency Map', use_container_width=True)\n",
        "\n",
        "\n",
        "    saliency_maps_path = f'saliency_maps/{uploaded_file.name}'\n",
        "    explanation= generate_explanation(saliency_maps_path, result, prediction[0][class_index])\n",
        "    st.write(\"##Explanation:\")\n",
        "    st.write(explanation)\n"
      ],
      "metadata": {
        "id": "eUoEFSOy4XQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill ngrok\n",
        "# ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# # Start the Streamlit server in a separate thread\n",
        "# thread = Thread(target=run_streamlit)\n",
        "# thread.start()"
      ],
      "metadata": {
        "id": "9cG20uy1NA8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile .env\n",
        "\n",
        "# GOOGLE_API_KEY ="
      ],
      "metadata": {
        "id": "m5P8kyLqw_tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "4nscrBXV5Gue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "id": "9QsVyZ1GM-Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run only if the tunnel is not able to run"
      ],
      "metadata": {
        "id": "UWg5eASpup7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "  print(f\"Clossing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "  ngrok.disconnect(tunnel.public_url)"
      ],
      "metadata": {
        "id": "VyolRrAHiFoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}